{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正規化\n",
    "+ バッチ正規化\n",
    "+ レイヤー正規化\n",
    "+ インスタンス正規化\n",
    "+ グループ正規化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### いつもの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/..\n",
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/..\n",
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/..\n"
     ]
    }
   ],
   "source": [
    "from type_hint import *\n",
    "from import_str import importstr\n",
    "from log_conf import logging\n",
    "log = logging.getLogger('nb')\n",
    "\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# running everything app\n",
    "def run(app, *argv):\n",
    "    argv = list(argv)\n",
    "    log.info('Running: {}({!r}).main()'.format(app, argv))\n",
    "    print(\"*app.rsplit('.', 1) : \", *app.rsplit('.', 1))\n",
    "\n",
    "    app_cls = importstr(*app.rsplit('.', 1)) # __import__を実行\n",
    "    app_cls(argv).main()\n",
    "\n",
    "    log.info(\"Finished: {}.({!r}).main()\".format(app, argv))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm1d (N, C) or (N, C, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:05,155 INFO     pid:4628 nb:013:run Running: Normalization.batch_norm.BatchNorm1dApp([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.batch_norm BatchNorm1dApp\n",
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/Normalization/..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,665 INFO     pid:4628 Normalization.batch_norm:044:main Starting BatchNorm1dApp, Namespace()\n",
      "2023-06-22 15:52:07,670 INFO     pid:4628 nb:019:run Finished: Normalization.batch_norm.BatchNorm1dApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N, C) input [L=1]--------------------------------------\n",
      "input_2dim.shape torch.Size([2, 3])\n",
      "input_2dim: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_2dim.shape torch.Size([2, 3])\n",
      "output_2dim: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<NativeBatchNormBackward0>)\n",
      "(N, C, L) input [Main]--------------------------------------\n",
      "input_3dim.shape torch.Size([2, 3, 4])\n",
      "input_3dim: \n",
      " tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_3dim.shape torch.Size([2, 3, 4])\n",
      "output_3dim: \n",
      " tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.batch_norm.BatchNorm1dApp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm2d (N, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,681 INFO     pid:4628 nb:013:run Running: Normalization.batch_norm.BatchNorm2dApp([]).main()\n",
      "2023-06-22 15:52:07,688 INFO     pid:4628 Normalization.batch_norm:108:main Starting BatchNorm2dApp, Namespace()\n",
      "2023-06-22 15:52:07,698 INFO     pid:4628 nb:019:run Finished: Normalization.batch_norm.BatchNorm2dApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.batch_norm BatchNorm2dApp\n",
      "(N, C, H, W) input [Main]--------------------------------------\n",
      "input_4dim.shape torch.Size([2, 3, 4, 4])\n",
      "input_4dim: \n",
      " tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_4dim.shape torch.Size([2, 3, 4, 4])\n",
      "output_4dim: \n",
      " tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.batch_norm.BatchNorm2dApp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm3d (N, C, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,732 INFO     pid:4628 nb:013:run Running: Normalization.batch_norm.BatchNorm3dApp([]).main()\n",
      "2023-06-22 15:52:07,753 INFO     pid:4628 Normalization.batch_norm:153:main Starting BatchNorm3dApp, Namespace()\n",
      "2023-06-22 15:52:07,778 INFO     pid:4628 nb:019:run Finished: Normalization.batch_norm.BatchNorm3dApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.batch_norm BatchNorm3dApp\n",
      "(N, C, D, H, W) input [Main]--------------------------------------\n",
      "input_5dim.shape torch.Size([2, 3, 4, 4, 4])\n",
      "input_5dim: \n",
      " tensor([[[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_5dim.shape torch.Size([2, 3, 4, 4, 4])\n",
      "output_5dim: \n",
      " tensor([[[[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]]]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.batch_norm.BatchNorm3dApp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LayerNorm (N, C, H, W), (N, C, D), etc = (N, *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,804 INFO     pid:4628 nb:013:run Running: Normalization.layer_norm.LayerNormApp([]).main()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,818 INFO     pid:4628 Normalization.layer_norm:044:main Starting LayerNormApp, Namespace()\n",
      "2023-06-22 15:52:07,824 INFO     pid:4628 nb:019:run Finished: Normalization.layer_norm.LayerNormApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.layer_norm LayerNormApp\n",
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/Normalization/..\n",
      "v_t.shape torch.Size([2, 3])\n",
      "v_t: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "v_t.mean((-2,-1)) tensor(3.5000)\n",
      "input.shape torch.Size([2, 3, 2, 2])\n",
      "input: \n",
      " tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]]])\n",
      "output.shape torch.Size([2, 3])\n",
      "output: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "gamma.shape torch.Size([2, 2])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "beta.shape torch.Size([2, 2])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], requires_grad=True)\n",
      "output_layer_nrom.shape torch.Size([2, 3, 2, 2])\n",
      "output_layer_nrom: \n",
      " tensor([[[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.layer_norm.LayerNormApp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InstanceNorm1d (N, C, L) or (C, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,841 INFO     pid:4628 nb:013:run Running: Normalization.instance_norm.InstanceNorm1dApp([]).main()\n",
      "2023-06-22 15:52:07,846 INFO     pid:4628 Normalization.instance_norm:044:main Starting InstanceNorm1dApp, Namespace()\n",
      "2023-06-22 15:52:07,854 INFO     pid:4628 nb:019:run Finished: Normalization.instance_norm.InstanceNorm1dApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.instance_norm InstanceNorm1dApp\n",
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/Normalization/..\n",
      "(C, L) input --------------------------------------\n",
      "input_2dim.shape torch.Size([3, 4])\n",
      "input_2dim: \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_2dim.shape torch.Size([3, 4])\n",
      "output_2dim: \n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], grad_fn=<SqueezeBackward1>)\n",
      "(N, C, L) input [Main]--------------------------------------\n",
      "input_3dim.shape torch.Size([2, 3, 4])\n",
      "input_3dim: \n",
      " tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "output_3dim.shape torch.Size([2, 3, 4])\n",
      "output_3dim: \n",
      " tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.instance_norm.InstanceNorm1dApp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InstanceNorm2d (N, C, H, W) or (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,870 INFO     pid:4628 nb:013:run Running: Normalization.instance_norm.InstanceNorm2dApp([]).main()\n",
      "2023-06-22 15:52:07,874 INFO     pid:4628 Normalization.instance_norm:114:main Starting InstanceNorm2dApp, Namespace()\n",
      "2023-06-22 15:52:07,884 INFO     pid:4628 nb:019:run Finished: Normalization.instance_norm.InstanceNorm2dApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.instance_norm InstanceNorm2dApp\n",
      "(C, H, W) input --------------------------------------\n",
      "input_3dim.shape torch.Size([3, 4, 4])\n",
      "input_3dim: \n",
      " tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_3dim.shape torch.Size([3, 4, 4])\n",
      "output_3dim: \n",
      " tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]], grad_fn=<SqueezeBackward1>)\n",
      "(N, C, H, W) input [Main]----------------------------------\n",
      "input_4dim.shape torch.Size([2, 3, 4, 4])\n",
      "input_4dim: \n",
      " tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "output_4dim.shape torch.Size([2, 3, 4, 4])\n",
      "output_4dim: \n",
      " tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.instance_norm.InstanceNorm2dApp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InstanceNorm3d (N, C, D, H, W) or (C, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,914 INFO     pid:4628 nb:013:run Running: Normalization.instance_norm.InstanceNorm3dApp([]).main()\n",
      "2023-06-22 15:52:07,930 INFO     pid:4628 Normalization.instance_norm:182:main Starting InstanceNorm3dApp, Namespace()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.instance_norm InstanceNorm3dApp\n",
      "(C, D, H, W) input [Main]----------------------------------\n",
      "input_4dim.shape torch.Size([3, 4, 4, 4])\n",
      "input_4dim: \n",
      " tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "gamma.shape torch.Size([3])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([3])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "output_4dim.shape torch.Size([3, 4, 4, 4])\n",
      "output_4dim: \n",
      " tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]], grad_fn=<SqueezeBackward1>)\n",
      "(N, C, D, H, W) input [Main]--------------------------------------\n",
      "input_5dim.shape torch.Size([2, 3, 4, 4, 4])\n",
      "input_5dim: \n",
      " tensor([[[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:07,962 INFO     pid:4628 nb:019:run Finished: Normalization.instance_norm.InstanceNorm3dApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_5dim.shape torch.Size([2, 3, 4, 4, 4])\n",
      "output_5dim: \n",
      " tensor([[[[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]]]]])\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.instance_norm.InstanceNorm3dApp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupNorm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupNorm (N, C, *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:08,040 INFO     pid:4628 nb:013:run Running: Normalization.group_norm.GroupNormApp([]).main()\n",
      "2023-06-22 15:52:08,052 INFO     pid:4628 Normalization.group_norm:044:main Starting GroupNormApp, Namespace()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*app.rsplit('.', 1) :  Normalization.group_norm GroupNormApp\n",
      "module_parent_dir /Users/inoueshinichi/Desktop/MyGithub/Wiki_AI/Normalization/..\n",
      "(N, C, H, W) input ------------------------------------\n",
      "input_4dim.shape torch.Size([2, 9, 2, 2])\n",
      "input_4dim: \n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:52:08,138 INFO     pid:4628 nb:019:run Finished: Normalization.group_norm.GroupNormApp.([]).main()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]]])\n",
      "gamma.shape torch.Size([9])\n",
      "gamma: \n",
      " Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "beta.shape torch.Size([9])\n",
      "beta: \n",
      " Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "run('Normalization.group_norm.GroupNormApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py38WorkEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
